{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test,y_test) = mnist.load_data()\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets visualize the first input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Adam optimizer\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "opt_1 = Adam(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 811us/step - loss: 0.3574 - accuracy: 0.9008 - val_loss: 0.2886 - val_accuracy: 0.9209\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 760us/step - loss: 0.2891 - accuracy: 0.9192 - val_loss: 0.2771 - val_accuracy: 0.9234\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 760us/step - loss: 0.2761 - accuracy: 0.9225 - val_loss: 0.2687 - val_accuracy: 0.9242\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 765us/step - loss: 0.2689 - accuracy: 0.9247 - val_loss: 0.2663 - val_accuracy: 0.9256\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.2637 - accuracy: 0.9267 - val_loss: 0.2668 - val_accuracy: 0.9277\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 765us/step - loss: 0.2595 - accuracy: 0.9276 - val_loss: 0.2677 - val_accuracy: 0.9265\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 758us/step - loss: 0.2561 - accuracy: 0.9294 - val_loss: 0.2637 - val_accuracy: 0.9279\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 765us/step - loss: 0.2542 - accuracy: 0.9304 - val_loss: 0.2638 - val_accuracy: 0.9278\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 796us/step - loss: 0.2519 - accuracy: 0.9307 - val_loss: 0.2651 - val_accuracy: 0.9276\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 769us/step - loss: 0.2503 - accuracy: 0.9310 - val_loss: 0.2664 - val_accuracy: 0.9275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c514ccc1c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base Model (Model 1)\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model_1 = Sequential([layers.Input((28,28)),\n",
    "                     layers.Lambda(lambda x:x / 255),\n",
    "                      layers.Flatten(),\n",
    "                      layers.Dense(10, activation='softmax')\n",
    "                     ])\n",
    "\n",
    "model_1.compile(optimizer = opt_1, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(X_train, y_train,validation_data = (X_test, y_test)\n",
    "            ,epochs=10)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 871us/step - loss: 0.3536 - accuracy: 0.8998 - val_loss: 0.2110 - val_accuracy: 0.9389\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 832us/step - loss: 0.1882 - accuracy: 0.9461 - val_loss: 0.1609 - val_accuracy: 0.9535\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 836us/step - loss: 0.1470 - accuracy: 0.9577 - val_loss: 0.1382 - val_accuracy: 0.9597\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 836us/step - loss: 0.1234 - accuracy: 0.9638 - val_loss: 0.1212 - val_accuracy: 0.9639\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 837us/step - loss: 0.1073 - accuracy: 0.9682 - val_loss: 0.1167 - val_accuracy: 0.9639\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 839us/step - loss: 0.0952 - accuracy: 0.9716 - val_loss: 0.1149 - val_accuracy: 0.9654\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 834us/step - loss: 0.0857 - accuracy: 0.9744 - val_loss: 0.1061 - val_accuracy: 0.9673\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 835us/step - loss: 0.0785 - accuracy: 0.9758 - val_loss: 0.1065 - val_accuracy: 0.9675\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 833us/step - loss: 0.0729 - accuracy: 0.9779 - val_loss: 0.1000 - val_accuracy: 0.9692\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 837us/step - loss: 0.0677 - accuracy: 0.9797 - val_loss: 0.1014 - val_accuracy: 0.9693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c513cc0588>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding number of parameters (Model 2)\n",
    "\n",
    "opt_2 = Adam(learning_rate = 0.001)\n",
    "\n",
    "model_2 = Sequential([layers.Input((28,28)),\n",
    "                     layers.Lambda(lambda x:x / 255),\n",
    "                      layers.Flatten(),\n",
    "                      layers.Dense(32,activation = 'relu'),\n",
    "                      layers.Dense(10,activation = 'softmax')\n",
    "                     ])\n",
    "\n",
    "model_2.compile(optimizer=opt_2, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model_2.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.0848 - accuracy: 0.6725 - val_loss: 1.2984 - val_accuracy: 0.5547\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 945us/step - loss: 1.4080 - accuracy: 0.5230 - val_loss: 1.3304 - val_accuracy: 0.5405\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 943us/step - loss: 1.3431 - accuracy: 0.5399 - val_loss: 1.4583 - val_accuracy: 0.5351\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 960us/step - loss: 1.4029 - accuracy: 0.5175 - val_loss: 1.4436 - val_accuracy: 0.5193\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 978us/step - loss: 1.4430 - accuracy: 0.4985 - val_loss: 1.5694 - val_accuracy: 0.4413\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 983us/step - loss: 1.4180 - accuracy: 0.5096 - val_loss: 1.5709 - val_accuracy: 0.4968\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 969us/step - loss: 1.3699 - accuracy: 0.5165 - val_loss: 1.6191 - val_accuracy: 0.5354\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 960us/step - loss: 1.4210 - accuracy: 0.5097 - val_loss: 1.4824 - val_accuracy: 0.5016\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 957us/step - loss: 1.3659 - accuracy: 0.5132 - val_loss: 1.6882 - val_accuracy: 0.5132\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 961us/step - loss: 1.3510 - accuracy: 0.5321 - val_loss: 1.7219 - val_accuracy: 0.4948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c515f01fc8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increasing the Learning rate (Model 3)\n",
    "\n",
    "opt_3 = Adam(learning_rate = 0.1)\n",
    "\n",
    "model_3 = Sequential([layers.Input((28,28)),\n",
    "                     layers.Lambda(lambda x:x / 255),\n",
    "                      layers.Flatten(),\n",
    "                      layers.Dense(32,activation = 'relu'),\n",
    "                      layers.Dense(10,activation = 'softmax')\n",
    "                     ])\n",
    "\n",
    "model_3.compile(optimizer=opt_3, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model_3.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2249 - accuracy: 0.9319 - val_loss: 0.1401 - val_accuracy: 0.9544\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0965 - accuracy: 0.9705 - val_loss: 0.0992 - val_accuracy: 0.9699\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0721 - accuracy: 0.9773 - val_loss: 0.1029 - val_accuracy: 0.9700\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0554 - accuracy: 0.9823 - val_loss: 0.0691 - val_accuracy: 0.9786\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0446 - accuracy: 0.9857 - val_loss: 0.0850 - val_accuracy: 0.9781\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0389 - accuracy: 0.9880 - val_loss: 0.0764 - val_accuracy: 0.9777\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.0803 - val_accuracy: 0.9786\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0294 - accuracy: 0.9905 - val_loss: 0.0969 - val_accuracy: 0.9744\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 0.0850 - val_accuracy: 0.9799\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.1105 - val_accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c51700ac08>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increasing the number of parameters (Model 4)\n",
    "\n",
    "\n",
    "opt_4 = Adam(learning_rate = 0.001)\n",
    "\n",
    "model_4 = Sequential([layers.Input((28,28)),\n",
    "                     layers.Lambda(lambda x:x / 255),\n",
    "                      layers.Flatten(),\n",
    "                      layers.Dense(128, activation = 'relu'),\n",
    "                      layers.Dense(128, activation = 'relu'),\n",
    "                      layers.Dense(128,activation = 'relu'),\n",
    "                      layers.Dense(10,activation = 'softmax')\n",
    "                     ])\n",
    "\n",
    "model_4.compile(optimizer=opt_4, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model_4.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5085 - accuracy: 0.9227 - val_loss: 0.3186 - val_accuracy: 0.9574\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2982 - accuracy: 0.9574 - val_loss: 0.2748 - val_accuracy: 0.9575\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2580 - accuracy: 0.9621 - val_loss: 0.2280 - val_accuracy: 0.9677\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2402 - accuracy: 0.9643 - val_loss: 0.2283 - val_accuracy: 0.9664\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2310 - accuracy: 0.9658 - val_loss: 0.2165 - val_accuracy: 0.9692\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2249 - accuracy: 0.9660 - val_loss: 0.2144 - val_accuracy: 0.9691\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2199 - accuracy: 0.9670 - val_loss: 0.2003 - val_accuracy: 0.9716\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2138 - accuracy: 0.9675 - val_loss: 0.1993 - val_accuracy: 0.9701\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2119 - accuracy: 0.9679 - val_loss: 0.1924 - val_accuracy: 0.9737\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2090 - accuracy: 0.9678 - val_loss: 0.2459 - val_accuracy: 0.9576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c5171e3c48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Regularization / Dropout to reduce overfitting\n",
    "\n",
    "from tensorflow.keras.regularizers import L2\n",
    "\n",
    "opt_5 = Adam(learning_rate = 0.001)\n",
    "\n",
    "model_5 = Sequential([layers.Input((28,28)),\n",
    "                      layers.Lambda(lambda x:x/255),\n",
    "                      layers.Flatten(),\n",
    "                      layers.Dense(128,activation = 'relu',kernel_regularizer=L2(0.001)),\n",
    "                      layers.Dropout(0.05),\n",
    "                      layers.Dense(128,activation = 'relu', kernel_regularizer=L2(0.001)),\n",
    "                      layers.Dropout(0.05),\n",
    "                      layers.Dense(128, activation = 'relu', kernel_regularizer=L2(0.001)),\n",
    "                      layers.Dropout(0.05),\n",
    "                      layers.Dense(10,activation='softmax')\n",
    "                     ])\n",
    "\n",
    "model_5.compile(optimizer=opt_5, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_5.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2041 - accuracy: 0.9694 - val_loss: 0.2113 - val_accuracy: 0.9657\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2032 - accuracy: 0.9693 - val_loss: 0.1991 - val_accuracy: 0.9713\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2046 - accuracy: 0.9683 - val_loss: 0.2054 - val_accuracy: 0.9670\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2016 - accuracy: 0.9692 - val_loss: 0.1861 - val_accuracy: 0.9752\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1989 - accuracy: 0.9697 - val_loss: 0.1934 - val_accuracy: 0.9730\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1970 - accuracy: 0.9692 - val_loss: 0.1950 - val_accuracy: 0.9708\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1972 - accuracy: 0.9692 - val_loss: 0.1856 - val_accuracy: 0.9738\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1955 - accuracy: 0.9707 - val_loss: 0.1944 - val_accuracy: 0.9707\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1968 - accuracy: 0.9696 - val_loss: 0.1960 - val_accuracy: 0.9710\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1971 - accuracy: 0.9690 - val_loss: 0.1890 - val_accuracy: 0.9734\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1932 - accuracy: 0.9708 - val_loss: 0.1888 - val_accuracy: 0.9748\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1959 - accuracy: 0.9699 - val_loss: 0.1959 - val_accuracy: 0.9696\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1929 - accuracy: 0.9705 - val_loss: 0.1860 - val_accuracy: 0.9722\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1952 - accuracy: 0.9683 - val_loss: 0.1916 - val_accuracy: 0.9699\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1936 - accuracy: 0.9698 - val_loss: 0.1764 - val_accuracy: 0.9736\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1927 - accuracy: 0.9702 - val_loss: 0.1845 - val_accuracy: 0.9721\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1927 - accuracy: 0.9690 - val_loss: 0.1861 - val_accuracy: 0.9722\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1903 - accuracy: 0.9701 - val_loss: 0.1788 - val_accuracy: 0.9738\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1915 - accuracy: 0.9701 - val_loss: 0.1897 - val_accuracy: 0.9710\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1924 - accuracy: 0.9696 - val_loss: 0.1799 - val_accuracy: 0.9730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c514de4508>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increase number of epochs\n",
    "\n",
    "model_5.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
